import requests
from bs4 import BeautifulSoup
import time
import re
import json
import os
from datetime import datetime

BASE_URL = "https://tubitak.gov.tr"
ACTIVE_CALLS_URL = f"{BASE_URL}/tr/destekler/sanayi/ulusal-destek-programlari"

headers = {"User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64)"}


def clean_text(text):
    """Gereksiz boÅŸluklarÄ± ve satÄ±r sonlarÄ±nÄ± temizler"""
    text = re.sub(r"\s+", " ", text).strip()
    return text


def get_active_calls():
    """Aktif Ã§aÄŸrÄ±larÄ± Ã§eker ve dÃ¶ndÃ¼rÃ¼r."""
    print("ğŸ” Aktif Ã§aÄŸrÄ±lar kontrol ediliyor...")

    try:
        r = requests.get(ACTIVE_CALLS_URL, headers=headers)
        soup = BeautifulSoup(r.text, "html.parser")

        # Aktif Ã§aÄŸrÄ±lar container'Ä±nÄ± bul
        active_calls_container = soup.select_one("#block-feza-gursey-views-block-cagrilar-block-2")

        if not active_calls_container:
            print("âš ï¸ Aktif Ã§aÄŸrÄ±lar container'Ä± bulunamadÄ±.")
            return []

        # Ã‡aÄŸrÄ± linklerini bul
        call_links = active_calls_container.select(".views-row a[href]")

        active_calls = []
        for link in call_links:
            name = clean_text(link.get_text())
            href = link.get("href")

            if not href.startswith("http"):
                href = BASE_URL + href

            active_calls.append({"name": name, "url": href, "found_date": datetime.now().strftime("%Y-%m-%d %H:%M:%S")})

        print(f"âœ… {len(active_calls)} aktif Ã§aÄŸrÄ± bulundu.")
        return active_calls

    except Exception as e:
        print(f"âŒ Aktif Ã§aÄŸrÄ±lar Ã§ekilirken hata: {str(e)}")
        return []


def get_call_details(url):
    """Ã‡aÄŸrÄ± detay sayfasÄ±ndan 'Kimler BaÅŸvurabilir' bilgisini Ã§eker."""
    try:
        r = requests.get(url, headers=headers)
        soup = BeautifulSoup(r.text, "html.parser")

        # "Kimler BaÅŸvurabilir" baÅŸlÄ±ÄŸÄ±nÄ± bul
        basliklar = soup.select(".field--name-field-baslik.field__item")

        for baslik in basliklar:
            if "Kimler BaÅŸvurabilir" in baslik.get_text(strip=True):
                # Parent paragraph'Ä± bul
                parent_paragraph = baslik.find_parent("div", class_="paragraph")
                if parent_paragraph:
                    # Ä°Ã§erik alanÄ±nÄ± bul
                    icerik = parent_paragraph.select_one(".field--name-field-icerik.field__item")
                    if not icerik:
                        return None

                    # TÃ¼m iÃ§eriÄŸi birleÅŸtir
                    full_text_parts = []

                    # Ã–nce paragraflarÄ± al
                    for p in icerik.find_all("p"):
                        text = clean_text(p.get_text())
                        if text:
                            full_text_parts.append(text)

                    # Sonra liste elemanlarÄ±nÄ± al
                    for li in icerik.find_all("li"):
                        text = clean_text(li.get_text())
                        if text:
                            full_text_parts.append(text)

                    # EÄŸer hiÃ§bir ÅŸey bulunamadÄ±ysa, tÃ¼m iÃ§eriÄŸi al
                    if not full_text_parts:
                        full_text = clean_text(icerik.get_text())
                        if full_text:
                            full_text_parts = [full_text]

                    # TÃ¼m parÃ§alarÄ± birleÅŸtir
                    if full_text_parts:
                        return " ".join(full_text_parts)

                    return None
        return None

    except Exception as e:
        print(f"âŒ Ã‡aÄŸrÄ± detaylarÄ± Ã§ekilirken hata: {str(e)}")
        return None


def scrape_active_calls():
    """Aktif Ã§aÄŸrÄ±larÄ± Ã§eker (sadece isimler)."""
    print("ğŸš€ Aktif Ã§aÄŸrÄ±lar iÅŸleniyor...")

    # Aktif Ã§aÄŸrÄ±larÄ± Ã§ek
    active_calls = get_active_calls()

    if not active_calls:
        print("âš ï¸ Aktif Ã§aÄŸrÄ± bulunamadÄ±.")
        return None

    # RAG iÃ§in uygun JSON formatÄ±nda veri toplama
    rag_data = {"source": "TÃœBÄ°TAK Aktif Ã‡aÄŸrÄ±lar", "url": ACTIVE_CALLS_URL, "extraction_date": datetime.now().strftime("%Y-%m-%d %H:%M:%S"), "programs": []}

    for i, call in enumerate(active_calls, 1):
        print(f"[{i}/{len(active_calls)}] {call['name']}")

        program_data = {
            "program_name": call["name"],
            "program_url": call["url"],
            "applicant_requirements": "Aktif Ã§aÄŸrÄ± - detay Ã§ekilmedi",
            "status": "active_call",
            "found_date": call["found_date"],
        }

        rag_data["programs"].append(program_data)

    # JSON dosyasÄ±na kaydet
    with open("active_calls_data.json", "w", encoding="utf-8") as f:
        json.dump(rag_data, f, ensure_ascii=False, indent=2)

    print(f"\nâœ… Aktif Ã§aÄŸrÄ±lar 'active_calls_data.json' dosyasÄ±na kaydedildi.")
    print(f"âœ… Toplam {len(rag_data['programs'])} Ã§aÄŸrÄ± iÅŸlendi.")

    return rag_data


def check_active_calls_file():
    """active_calls_data.json dosyasÄ±nÄ±n varlÄ±ÄŸÄ±nÄ± kontrol eder."""
    return os.path.exists("active_calls_data.json")


def get_active_calls_data():
    """active_calls_data.json dosyasÄ±nÄ± okur."""
    try:
        with open("active_calls_data.json", "r", encoding="utf-8") as f:
            return json.load(f)
    except (FileNotFoundError, json.JSONDecodeError):
        return None
